{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deep_recommender_embeddings.src.ares import request_asset_from_ares\n",
    "from deep_recommender_embeddings.src.elasticsearch_utils import get_es_instance, get_data_from_es, print_item\n",
    "from deep_recommender_embeddings.src.image_embeddings import generate_image_embeddings\n",
    "from deep_recommender_embeddings.src.models import ItemSimilarityModel\n",
    "from deep_recommender_embeddings.src.plotting import plot_metric\n",
    "from deep_recommender_embeddings.src.tf_utils import get_tf_lookup_table_for_property, get_tf_lookup_for_dict\n",
    "from deep_recommender_embeddings.src.inference import get_dict_of_embeddings, build_annoy_index\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from deep_recommender_embeddings.src.preprocessing import load_data, clean_data, filter_logs, get_pairs, \\\n",
    "    get_item_pairs_from_journeys, generate_model_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#%reload_ext autoreload\n",
    "\n",
    "#reload(deep_recommender_embeddings.src.tf_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load content data from ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "_es_index = 'sfv_02112020'\n",
    "_es_host = 'localhost'\n",
    "_es_port = '9200'\n",
    "es = get_es_instance(es_host=_es_host, es_port=_es_port)\n",
    "\n",
    "# This is the imaginary date that recommendations will begenerated on\n",
    "prediction_time = \"2020-11-02T00:00:00\"\n",
    "\n",
    "# Business rules usually prevent recs being returned that are older than 90 days so we will only retrieve items\n",
    "# that were published within this time window\n",
    "max_age_days = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's fetch all the relevant data from elasticsearch. For all items in the publication window we will fetch the id,\n",
    "all the text, the tags, the category and the image url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "Grabbed 5060 items from elasticsearch\n"
     ]
    }
   ],
   "source": [
    "features = [\"combinedBodySummaryHeadline\",\"tagsText\", \"articleCategoryName\", \"thumbnailUrl\"]\n",
    "hits = get_data_from_es(es, features, 30000, 5000, prediction_time, max_age_days, _es_index)\n",
    "unique_item_ids = [hit['sort'][0] for hit in hits]\n",
    "print(f'Grabbed {len(unique_item_ids)} items from elasticsearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate tensorflow lookup tables\n",
    "Tensorflow requires special lookup tables to use in its graph so here we extract the relevant information into these\n",
    "objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow lookup table created for combinedBodySummaryHeadline with 5060 entries.\n",
      "Tensorflow lookup table created for tagsText with 3544 entries.\n",
      "Tensorflow lookup table created for articleCategoryName with 4527 entries.\n",
      "Tensorflow lookup table created for thumbnailUrl with 5060 entries.\n"
     ]
    }
   ],
   "source": [
    "body_lookup_table, _ = get_tf_lookup_table_for_property(hits, \"combinedBodySummaryHeadline\", clean=True)\n",
    "tags_lookup_table, _ = get_tf_lookup_table_for_property(hits, \"tagsText\")\n",
    "category_lookup_table, unique_categories = get_tf_lookup_table_for_property(hits, \"articleCategoryName\")\n",
    "thumbnail_lookup_table, _ = get_tf_lookup_table_for_property(hits, \"thumbnailUrl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate image embeddings with pretrained model and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_link = 'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4'\n",
    "embeddings_fpath = '../data/embeddings/image/mobilenet_v2_140_224.pk'\n",
    "IMAGE_SHAPE = (224,224)\n",
    "generate_embeddings = False\n",
    "\n",
    "if generate_embeddings:\n",
    "    im_embeddings = generate_image_embeddings(model_link, thumbnail_lookup_table, IMAGE_SHAPE, unique_item_ids)\n",
    "    with open(embeddings_fpath, 'wb') as f:\n",
    "        pickle.dump(im_embeddings, f)\n",
    "else:\n",
    "    with open(embeddings_fpath, 'rb') as f:\n",
    "        im_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow lookup table created for vector dim=(1792,) with 5060 entries.\n"
     ]
    }
   ],
   "source": [
    "im_vec_lookup_table = get_tf_lookup_for_dict(im_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# inp = body_lookup_table.lookup(tf.convert_to_tensor(['/news/uk-england-nottinghamshire-54731548', '/news/election-us-2020-54754797']))\n",
    "# TEXT_MODEL_LINK = 'https://tfhub.dev/tensorflow/albert_en_large/2'\n",
    "# #TEXT_MODEL_LINK = 'https://tfhub.dev/google/nnlm-en-dim50/2'\n",
    "# TEXT_MODEL_LINK = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1'\n",
    "\n",
    "# text_model_embedding = tf.keras.Sequential([\n",
    "#     hub.KerasLayer(TEXT_MODEL_LINK,input_shape=[],\n",
    "#                 dtype=tf.string, trainable=False),\n",
    "# #    tf.keras.layers.Embedding(input_dim=50, output_dim=embedding_dim, name=\"text_model_embedding_layer\"),\n",
    "# #    tf.keras.layers.GlobalAveragePooling1D(name=\"text_model_global_averaging_pooling_layer\")\n",
    "#     ])\n",
    "# text_model_embedding(inp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the user data\n",
    "Load the vocabulary of the of item IDs into a tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/mercef02/Projects/datasets_models/sfv_user_user_zoom_20201026_20201102/sfv_user*' #'/Users/mercef02/Projects/datasets/sfv_user_week_compact/*.csv'\n",
    "logs = load_data(d_path=DATA_PATH, stop_after_n_files=1)\n",
    "logs = clean_data(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original interactions: 2441510\n",
      "Date filtered interactions: 161335\n",
      "Minimum mention filtered interactions  : 146738\n",
      "Interactions filtered for items existing in ES : 108230\n"
     ]
    }
   ],
   "source": [
    "min_date = pd.to_datetime('2020-11-01T00:00:00')\n",
    "max_date = pd.to_datetime('2020-11-01T11:59:59')\n",
    "min_mentions = 5\n",
    "train_logs = filter_logs(logs, min_date, max_date, min_mentions, unique_item_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate item pairs \n",
    "The input for the model is pairs of consecutively consumed items so next we need to convert the journeys into item pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of item pairs: 6249\n"
     ]
    }
   ],
   "source": [
    "train_pairs = get_item_pairs_from_journeys(train_logs)\n",
    "train_pairs_df = pd.DataFrame(train_pairs)\n",
    "train_logs_tf = tf.data.Dataset.from_tensor_slices(dict(train_pairs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise what some of these pairs of items look like that will be useful later for a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_a</th>\n",
       "      <th>item_b</th>\n",
       "      <th>shingled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/news/business-54746208</td>\n",
       "      <td>/news/world-asia-54734067</td>\n",
       "      <td>/news/business-54746208_/news/world-asia-54734067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/news/world-asia-54734067</td>\n",
       "      <td>/news/world-53405538</td>\n",
       "      <td>/news/world-asia-54734067_/news/world-53405538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/news/election-us-2020-54754800</td>\n",
       "      <td>/news/election-us-2020-54754652</td>\n",
       "      <td>/news/election-us-2020-54754800_/news/election...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/news/world-54754565</td>\n",
       "      <td>/sport/54122112</td>\n",
       "      <td>/news/world-54754565_/sport/54122112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/news/election-us-2020-54754800</td>\n",
       "      <td>/news/election-us-2020-54754797</td>\n",
       "      <td>/news/election-us-2020-54754800_/news/election...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            item_a                           item_b  \\\n",
       "0          /news/business-54746208        /news/world-asia-54734067   \n",
       "1        /news/world-asia-54734067             /news/world-53405538   \n",
       "2  /news/election-us-2020-54754800  /news/election-us-2020-54754652   \n",
       "3             /news/world-54754565                  /sport/54122112   \n",
       "4  /news/election-us-2020-54754800  /news/election-us-2020-54754797   \n",
       "\n",
       "                                            shingled  \n",
       "0  /news/business-54746208_/news/world-asia-54734067  \n",
       "1     /news/world-asia-54734067_/news/world-53405538  \n",
       "2  /news/election-us-2020-54754800_/news/election...  \n",
       "3               /news/world-54754565_/sport/54122112  \n",
       "4  /news/election-us-2020-54754800_/news/election...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs_df['shingled'] = train_pairs_df['item_a'] + '_' + train_pairs_df['item_b']\n",
    "vc = train_pairs_df.shingled.value_counts()\n",
    "train_pairs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we are visualising the histogram of the item pairs ordered by their frequency.\n",
    "vc.head(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original interactions: 2441510\n",
      "Date filtered interactions: 257384\n",
      "Minimum mention filtered interactions  : 234998\n",
      "Interactions filtered for items existing in ES : 171466\n",
      "Total number of item pairs: 9824\n",
      "Total number of holdout item pairs: 9824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_date = pd.to_datetime('2020-11-01T12:00:00')\n",
    "max_date = pd.to_datetime('2020-11-02T00:00:00')\n",
    "min_mentions = 5\n",
    "holdout_logs = filter_logs(logs, min_date, max_date, min_mentions, unique_item_ids)\n",
    "holdout_pairs = get_item_pairs_from_journeys(holdout_logs)\n",
    "print(f\"Total number of holdout item pairs: {len(holdout_pairs)}\")\n",
    "holdout_logs_tf = tf.data.Dataset.from_tensor_slices(dict(pd.DataFrame(holdout_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train pairs: 5624\n",
      "Number of test pairs: 625\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "training_shuffled = train_logs_tf.shuffle(buffer_size=100_000, seed=42, reshuffle_each_iteration=False)\n",
    "train_pc = 0.9\n",
    "test_pc = 0.1\n",
    "sfv_train = training_shuffled.take(np.floor(len(training_shuffled)*train_pc))\n",
    "sfv_val = training_shuffled.skip(np.floor(len(training_shuffled)*train_pc))\n",
    "print(f'Number of train pairs: {len(sfv_train)}')\n",
    "print(f'Number of test pairs: {len(sfv_val)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "44/44 [==============================] - 5s 104ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0116 - factorized_top_k/top_5_categorical_accuracy: 0.0217 - factorized_top_k/top_10_categorical_accuracy: 0.0288 - factorized_top_k/top_50_categorical_accuracy: 0.0539 - factorized_top_k/top_100_categorical_accuracy: 0.0717 - loss: 5.0821 - regularization_loss: 0.0000e+00 - total_loss: 5.0821 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4.7223 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.7223\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 5s 106ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0020 - factorized_top_k/top_100_categorical_accuracy: 0.0021 - loss: 4.8464 - regularization_loss: 0.0000e+00 - total_loss: 4.8464 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4.7183 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.7183\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 6s 144ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0020 - factorized_top_k/top_100_categorical_accuracy: 0.0021 - loss: 4.8423 - regularization_loss: 0.0000e+00 - total_loss: 4.8423 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4.7134 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.7134\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 5s 116ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0020 - factorized_top_k/top_100_categorical_accuracy: 0.0021 - loss: 4.8372 - regularization_loss: 0.0000e+00 - total_loss: 4.8372 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 4.7072 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.7072\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 5s 117ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0023 - factorized_top_k/top_100_categorical_accuracy: 0.0092 - loss: 4.8306 - regularization_loss: 0.0000e+00 - total_loss: 4.8306 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0080 - val_loss: 4.6990 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.6990\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 4s 96ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0112 - factorized_top_k/top_100_categorical_accuracy: 0.0132 - loss: 4.8219 - regularization_loss: 0.0000e+00 - total_loss: 4.8219 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0080 - val_factorized_top_k/top_100_categorical_accuracy: 0.0160 - val_loss: 4.6877 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.6877\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 4s 101ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0018 - factorized_top_k/top_50_categorical_accuracy: 0.0137 - factorized_top_k/top_100_categorical_accuracy: 0.0276 - loss: 4.8096 - regularization_loss: 0.0000e+00 - total_loss: 4.8096 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0080 - val_factorized_top_k/top_50_categorical_accuracy: 0.0080 - val_factorized_top_k/top_100_categorical_accuracy: 0.0272 - val_loss: 4.6710 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.6710\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 5s 106ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0082 - factorized_top_k/top_10_categorical_accuracy: 0.0101 - factorized_top_k/top_50_categorical_accuracy: 0.0208 - factorized_top_k/top_100_categorical_accuracy: 0.0388 - loss: 4.7906 - regularization_loss: 0.0000e+00 - total_loss: 4.7906 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0080 - val_factorized_top_k/top_10_categorical_accuracy: 0.0080 - val_factorized_top_k/top_50_categorical_accuracy: 0.0176 - val_factorized_top_k/top_100_categorical_accuracy: 0.0432 - val_loss: 4.6436 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.6436\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 4s 100ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0096 - factorized_top_k/top_5_categorical_accuracy: 0.0124 - factorized_top_k/top_10_categorical_accuracy: 0.0135 - factorized_top_k/top_50_categorical_accuracy: 0.0331 - factorized_top_k/top_100_categorical_accuracy: 0.0576 - loss: 4.7575 - regularization_loss: 0.0000e+00 - total_loss: 4.7575 - val_factorized_top_k/top_1_categorical_accuracy: 0.0080 - val_factorized_top_k/top_5_categorical_accuracy: 0.0096 - val_factorized_top_k/top_10_categorical_accuracy: 0.0096 - val_factorized_top_k/top_50_categorical_accuracy: 0.0224 - val_factorized_top_k/top_100_categorical_accuracy: 0.0624 - val_loss: 4.5905 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.5905\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 4s 99ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0130 - factorized_top_k/top_5_categorical_accuracy: 0.0142 - factorized_top_k/top_10_categorical_accuracy: 0.0144 - factorized_top_k/top_50_categorical_accuracy: 0.0430 - factorized_top_k/top_100_categorical_accuracy: 0.0978 - loss: 4.7024 - regularization_loss: 0.0000e+00 - total_loss: 4.7024 - val_factorized_top_k/top_1_categorical_accuracy: 0.0032 - val_factorized_top_k/top_5_categorical_accuracy: 0.0096 - val_factorized_top_k/top_10_categorical_accuracy: 0.0096 - val_factorized_top_k/top_50_categorical_accuracy: 0.0544 - val_factorized_top_k/top_100_categorical_accuracy: 0.1152 - val_loss: 4.4882 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.4882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.09779516607522964\n",
      "Validation accuracy: 0.1151999980211258\n",
      "Hold out metrics:\n",
      "77/77 [==============================] - 7s 95ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0051 - factorized_top_k/top_10_categorical_accuracy: 0.0092 - factorized_top_k/top_50_categorical_accuracy: 0.0353 - factorized_top_k/top_100_categorical_accuracy: 0.0837 - loss: 4.7524 - regularization_loss: 0.0000e+00 - total_loss: 4.7524\n",
      "Holdout accuracy: 0.08367263525724411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0030537459533661604,\n",
       " 0.005089576356112957,\n",
       " 0.009161237627267838,\n",
       " 0.035321660339832306,\n",
       " 0.08367263525724411,\n",
       " 4.453891277313232,\n",
       " 0,\n",
       " 4.453891277313232]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim50/2'\n",
    "model = {\"format\": \"text\", \"link\": model_link}\n",
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_val.batch(128).cache()\n",
    "model_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['image_embedding'],\n",
    "                                      feature_dims=[1792],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_vec_lookup_table,\n",
    "                                      layer_sizes=[64],\n",
    "                                      pretrained_text_model=model_link)\n",
    "model_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "one_layer_history = model_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "plot_metric(one_layer_history, 'factorized_top_k/top_10_categorical_accuracy')\n",
    "print(\"Hold out metrics:\")\n",
    "metrics = model_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "print(f'Holdout accuracy: {metrics[4]}')\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_embeddings_fpath = '../data/embeddings/trained/body_category_64.pkl'\n",
    "item_embeddings = get_dict_of_embeddings(model_one_layer, unique_item_ids, save_fpath=None)\n",
    "annoy_index, id_to_uri, uri_to_id = build_annoy_index(item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, values = im_vec_lookup_table.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1792,)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.numpy()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_uri = /news/election-us-2020-54754797\n",
      "groundtruth_uri = /news/uk-england-nottinghamshire-54731548\n",
      "Generating recommendations for:\n",
      "/news/election-us-2020-54754797 \n",
      " Just ahead of the election, the US is seeing what could be the largest outbreak of the pandemic so far.\n",
      "-------------------\n",
      "-------------------\n",
      "LITMUS TEST: False\n",
      "-------------------\n",
      "-------------------\n",
      "/news/election-us-2020-54754797 \n",
      " Just ahead of the election, the US is seeing what could be the largest outbreak of the pandemic so far.\n",
      "-------------------\n",
      "/news/uk-england-cumbria-54283113 \n",
      " Barber John Ritson is urging people to stay safe after his friend Jimmy succumbed to coronavirus.\n",
      "-------------------\n",
      "/naidheachdan/54577901 \n",
      " Thòisich iomairt an t-seachdain seo gus clach-uaigh an t-seinneadair Gàidhlig Seasaidh NicLachlainn a stèidheachadh às ùr.\n",
      "-------------------\n",
      "/newsround/54246293 \n",
      " Eleven-year-old Austin is on a mission to get more people wearing clear face masks to help deaf people.\n",
      "-------------------\n",
      "/news/uk-54780634 \n",
      " Faith Mason‘s son, Neil Martin, was severely disabled, unable to walk and talk. He died in 1969. An undercover officer used his names to create a fake identity.\n",
      "-------------------\n",
      "/news/uk-54034805 \n",
      " The parents of the youngest victim of the Manchester Arena terror attack speak about their feelings, ahead of a public inquiry.\n",
      "-------------------\n",
      "/news/uk-scotland-54848202 \n",
      " Two families have been displaced after extensive damage to the properties in Motherwell.\n",
      "-------------------\n",
      "/news/uk-england-cambridgeshire-54792528 \n",
      " A tech firm is working on an antenna system that could be mounted on drones flying at 60,000ft.\n",
      "-------------------\n",
      "/news/health-53941987 \n",
      " A hospital in Jerusalem is recruiting recovered Covid-19 patients to visit people who would otherwise be in isolation.\n",
      "-------------------\n",
      "/news/uk-england-lincolnshire-53822696 \n",
      " The phenomenon can be prompted by the intense thundery weather seen across parts of the UK recently.\n",
      "-------------------\n",
      "/newsround/53691590 \n",
      " Much of the UK is going to be getting back to sunshine and warm weather this weekend, so we asked our BBC Weather friends who'll get the best of it.\n",
      "-------------------\n",
      "/news/uk-northern-ireland-54479825 \n",
      " Shoppers and business owners in Downpatrick, Omagh and Londonderry react to increases in Covid fines.\n",
      "-------------------\n",
      "/news/world-us-canada-54171351 \n",
      " A look at the impact of wildfire smoke, as it increasingly becomes a source of air pollution.\n",
      "-------------------\n",
      "/news/science-environment-54010338 \n",
      " After a flight failure in 2019, the Vega rocket executes a flawless deployment of 53 satellites.\n",
      "-------------------\n",
      "/news/business-53712679 \n",
      " Starting with the epicentre, we follow how the blast ripped through the city, bringing life to a halt.\n",
      "-------------------\n",
      "/newsround/54463391 \n",
      " Do you like adventure, mystery and princesses who are also spies? Yes, then this book might be for you.\n",
      "-------------------\n",
      "/news/world-53870992 \n",
      " Baby pandas, leopard cubs and Europe's biggest mural. Some of the stories you may have missed this week.\n",
      "-------------------\n",
      "/news/world-australia-50482858 \n",
      " Bushfires are spreading across Australia's east coast, ravaging the marsupial's main habitat.\n",
      "-------------------\n",
      "/news/election-us-2020-54665415 \n",
      " Paul and Kayleah live in two different political bubbles, but they've found a place to vent online.\n",
      "-------------------\n",
      "/news/uk-northern-ireland-54599785 \n",
      " BBC NI's roving reporter James Boyce investigates claims that fairies have been spotted in County Tyrone.\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "#query_uri = '/news/technology-53018000'\n",
    "#query_uri = '/sport/football/53805003'\n",
    "#query_uri = '/news/business-10665047'\n",
    "#query_uri = '/news/uk-england-hampshire-53838761'\n",
    "\n",
    "query_uri, groundtruth_uri = vc.index[1].split('_')\n",
    "print(f'query_uri = {query_uri}')\n",
    "print(f'groundtruth_uri = {groundtruth_uri}')\n",
    "\n",
    "rec_uris = generate_model_recs(query_uri, annoy_index, uri_to_id, id_to_uri, item_embeddings, es, _es_index, 20)\n",
    "print(f'LITMUS TEST: {groundtruth_uri in rec_uris}')\n",
    "print('-------------------')\n",
    "print('-------------------')\n",
    "\n",
    "for rec in rec_uris:\n",
    "    print_item(rec, es, _es_index)\n",
    "    print('-------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pretrained text model nnlm 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained text model nnlm 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained TEXT model: https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\n",
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x19e50cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x19e50cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x19e50cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x19e50cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552/552 [==============================] - 219s 397ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0271 - factorized_top_k/top_10_categorical_accuracy: 0.0426 - factorized_top_k/top_50_categorical_accuracy: 0.1208 - factorized_top_k/top_100_categorical_accuracy: 0.1472 - loss: 13.6282 - regularization_loss: 0.0000e+00 - total_loss: 13.6282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001458283164538443,\n",
       " 0.027098583057522774,\n",
       " 0.042615849524736404,\n",
       " 0.12076850235462189,\n",
       " 0.14720165729522705]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_link = 'https://tfhub.dev/google/nnlm-en-dim50/2'\n",
    "#model_link = 'https://tfhub.dev/tensorflow/albert_en_large/2'\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "\n",
    "model = {\"format\": \"text\", \"link\": model_link}\n",
    "recsys2 = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['text_model'],\n",
    "                                      feature_dims=[model],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      layer_sizes=[],\n",
    "                                      pretrained_text_model=model_link)\n",
    "recsys2.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "recsys2_metrics = recsys2.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "recsys2_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained image model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained IMAGE model: https://tfhub.dev/google/imagenet/mobilenet_v2_100_96/feature_vector/4\n",
      "552/552 [==============================] - 79s 143ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0031 - factorized_top_k/top_10_categorical_accuracy: 0.0120 - factorized_top_k/top_50_categorical_accuracy: 0.0499 - factorized_top_k/top_100_categorical_accuracy: 0.0787 - loss: 13.6808 - regularization_loss: 0.0000e+00 - total_loss: 13.6808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.003086463548243046,\n",
       " 0.01203437615185976,\n",
       " 0.04990726336836815,\n",
       " 0.07871897518634796]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recsys2_im = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['image_embedding'],\n",
    "                                      feature_dims=[None],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "recsys2_im.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "recsys2_im_metrics = recsys2_im.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "recsys2_im_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-6-e48051f929fe>:177 call  *\n        return self.dense_layers(feature_embedding)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__  **\n        self.name)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:168 assert_input_compatibility\n        layer_name + ' is incompatible with the layer: '\n\n    ValueError: Input 0 of layer sequential_deep is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-71-735d35459e24>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m                                       \u001B[0mitem_image_lookup\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mthumbnail_lookup_table\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m                                       \u001B[0mimage_embedding_lookup_table\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mim_vec_lookup_table\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m                                       layer_sizes=[512, 100])\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0mrecsys2_im\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptimizers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAdagrad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mrecsys2_im_metrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrecsys2_im\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mholdout_logs_tf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcache\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-e48051f929fe>\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, test_candidate_ids, features, feature_dims, unique_item_ids, item_body_lookup, item_tags_lookup, item_category_lookup, item_image_lookup, image_embedding_lookup_table, layer_sizes, pretrained_text_model, pretrained_image_model, compute_metrics)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    223\u001B[0m     self.task = tfrs.tasks.Retrieval(loss=tf.keras.losses.CategoricalCrossentropy(),\n\u001B[0;32m--> 224\u001B[0;31m             metrics=tfrs.metrics.FactorizedTopK(candidates=test_candidate_ids.batch(512).map(self.item_model)))\n\u001B[0m\u001B[1;32m    225\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    226\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mcompute_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_features\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mText\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, map_func, num_parallel_calls, deterministic)\u001B[0m\n\u001B[1;32m   1693\u001B[0m     \"\"\"\n\u001B[1;32m   1694\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mnum_parallel_calls\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1695\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mMapDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmap_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreserve_cardinality\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1696\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1697\u001B[0m       return ParallelMapDataset(\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001B[0m\n\u001B[1;32m   4043\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_transformation_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4044\u001B[0m         \u001B[0mdataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4045\u001B[0;31m         use_legacy_function=use_legacy_function)\n\u001B[0m\u001B[1;32m   4046\u001B[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001B[1;32m   4047\u001B[0m         \u001B[0minput_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variant_tensor\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[1;32m   3369\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mtracking\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresource_tracker_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresource_tracker\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3370\u001B[0m         \u001B[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3371\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwrapper_fn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_concrete_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3372\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0madd_to_graph\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3373\u001B[0m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_to_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mget_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2937\u001B[0m     \"\"\"\n\u001B[1;32m   2938\u001B[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001B[0;32m-> 2939\u001B[0;31m         *args, **kwargs)\n\u001B[0m\u001B[1;32m   2940\u001B[0m     \u001B[0mgraph_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_garbage_collector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelease\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2941\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2904\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2905\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2906\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2907\u001B[0m       \u001B[0mseen_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2908\u001B[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3212\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3213\u001B[0;31m       \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3214\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3215\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3073\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3074\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3075\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3076\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3077\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    985\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 986\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    987\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36mwrapper_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   3362\u001B[0m           attributes=defun_kwargs)\n\u001B[1;32m   3363\u001B[0m       \u001B[0;32mdef\u001B[0m \u001B[0mwrapper_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=missing-docstring\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3364\u001B[0;31m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_wrapper_helper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3365\u001B[0m         \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstructure\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_tensor_list\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output_structure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mret\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3366\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert_to_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mret\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001B[0m in \u001B[0;36m_wrapper_helper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m   3297\u001B[0m         \u001B[0mnested_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mnested_args\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3298\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3299\u001B[0;31m       \u001B[0mret\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mautograph\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtf_convert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mag_ctx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mnested_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3300\u001B[0m       \u001B[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3301\u001B[0m       \u001B[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    256\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'ag_error_metadata'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 258\u001B[0;31m           \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    259\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    260\u001B[0m           \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    <ipython-input-6-e48051f929fe>:177 call  *\n        return self.dense_layers(feature_embedding)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__  **\n        self.name)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:168 assert_input_compatibility\n        layer_name + ' is incompatible with the layer: '\n\n    ValueError: Input 0 of layer sequential_deep is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "recsys2_im = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['image_embedding'],\n",
    "                                      feature_dims=[2048],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_vec_lookup_table,\n",
    "                                      layer_sizes=[512, 100])\n",
    "recsys2_im.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "recsys2_im_metrics = recsys2_im.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "recsys2_im_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained image model and pretrained text model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained TEXT model: https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\n",
      "552/552 [==============================] - 197s 357ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0032 - factorized_top_k/top_10_categorical_accuracy: 0.0118 - factorized_top_k/top_50_categorical_accuracy: 0.0499 - factorized_top_k/top_100_categorical_accuracy: 0.0799 - loss: 13.6803 - regularization_loss: 0.0000e+00 - total_loss: 13.6803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0031855700071901083,\n",
       " 0.011836162768304348,\n",
       " 0.049864791333675385,\n",
       " 0.07985161989927292]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "\n",
    "recsys2_im = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['text_model', 'image_embedding'],\n",
    "                                      feature_dims=[text_model, None],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "recsys2_im.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "recsys2_im_metrics = recsys2_im.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "recsys2_im_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained text model tuned on siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pretrained TEXT model: https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1cc9a5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1cc9a5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1cc933ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x1cc933ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 503s 295ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0025 - factorized_top_k/top_5_categorical_accuracy: 0.0080 - factorized_top_k/top_10_categorical_accuracy: 0.0104 - factorized_top_k/top_50_categorical_accuracy: 0.0322 - factorized_top_k/top_100_categorical_accuracy: 0.0528 - loss: 5.5050 - regularization_loss: 0.0000e+00 - total_loss: 5.5050 - val_factorized_top_k/top_1_categorical_accuracy: 0.0034 - val_factorized_top_k/top_5_categorical_accuracy: 0.0132 - val_factorized_top_k/top_10_categorical_accuracy: 0.0135 - val_factorized_top_k/top_50_categorical_accuracy: 0.0477 - val_factorized_top_k/top_100_categorical_accuracy: 0.0808 - val_loss: 8.8002 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.8002\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 576s 338ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0160 - factorized_top_k/top_10_categorical_accuracy: 0.0219 - factorized_top_k/top_50_categorical_accuracy: 0.0493 - factorized_top_k/top_100_categorical_accuracy: 0.0855 - loss: 8.0315 - regularization_loss: 0.0000e+00 - total_loss: 8.0315 - val_factorized_top_k/top_1_categorical_accuracy: 0.0013 - val_factorized_top_k/top_5_categorical_accuracy: 0.0121 - val_factorized_top_k/top_10_categorical_accuracy: 0.0139 - val_factorized_top_k/top_50_categorical_accuracy: 0.0320 - val_factorized_top_k/top_100_categorical_accuracy: 0.0758 - val_loss: 6.4258 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.4258\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 538s 316ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0043 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0248 - factorized_top_k/top_50_categorical_accuracy: 0.0548 - factorized_top_k/top_100_categorical_accuracy: 0.0812 - loss: 7.5356 - regularization_loss: 0.0000e+00 - total_loss: 7.5356 - val_factorized_top_k/top_1_categorical_accuracy: 0.0050 - val_factorized_top_k/top_5_categorical_accuracy: 0.0187 - val_factorized_top_k/top_10_categorical_accuracy: 0.0233 - val_factorized_top_k/top_50_categorical_accuracy: 0.0549 - val_factorized_top_k/top_100_categorical_accuracy: 0.0827 - val_loss: 5.5172 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.5172\n",
      "Train accuracy: 0.08118979632854462\n",
      "Validation accuracy: 0.08267486095428467\n",
      "552/552 [==============================] - 164s 297ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0046 - factorized_top_k/top_5_categorical_accuracy: 0.0187 - factorized_top_k/top_10_categorical_accuracy: 0.0217 - factorized_top_k/top_50_categorical_accuracy: 0.0515 - factorized_top_k/top_100_categorical_accuracy: 0.0771 - loss: 6.9825 - regularization_loss: 0.0000e+00 - total_loss: 6.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004573062993586063,\n",
       " 0.018702836707234383,\n",
       " 0.021690193563699722,\n",
       " 0.05149297043681145,\n",
       " 0.07713326811790466]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "model_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['text_model'],\n",
    "                                      feature_dims=[text_model],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[64])\n",
    "model_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "one_layer_history = model_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "text_deep_metrics = model_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "text_deep_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese network trained with item body text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 636s 373ms/step - factorized_top_k/top_1_categorical_accuracy: 0.8308 - factorized_top_k/top_5_categorical_accuracy: 0.8766 - factorized_top_k/top_10_categorical_accuracy: 0.8979 - factorized_top_k/top_50_categorical_accuracy: 0.9320 - factorized_top_k/top_100_categorical_accuracy: 0.9441 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.2928 - val_factorized_top_k/top_5_categorical_accuracy: 0.4839 - val_factorized_top_k/top_10_categorical_accuracy: 0.4937 - val_factorized_top_k/top_50_categorical_accuracy: 0.4972 - val_factorized_top_k/top_100_categorical_accuracy: 0.5209 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 555s 326ms/step - factorized_top_k/top_1_categorical_accuracy: 0.4317 - factorized_top_k/top_5_categorical_accuracy: 0.4521 - factorized_top_k/top_10_categorical_accuracy: 0.4626 - factorized_top_k/top_50_categorical_accuracy: 0.4776 - factorized_top_k/top_100_categorical_accuracy: 0.4830 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 5.8531e-04 - val_factorized_top_k/top_5_categorical_accuracy: 5.8531e-04 - val_factorized_top_k/top_10_categorical_accuracy: 7.3164e-04 - val_factorized_top_k/top_50_categorical_accuracy: 0.0010 - val_factorized_top_k/top_100_categorical_accuracy: 0.0018 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 523s 307ms/step - factorized_top_k/top_1_categorical_accuracy: 0.4392 - factorized_top_k/top_5_categorical_accuracy: 0.4724 - factorized_top_k/top_10_categorical_accuracy: 0.4893 - factorized_top_k/top_50_categorical_accuracy: 0.5148 - factorized_top_k/top_100_categorical_accuracy: 0.5244 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 1.4633e-04 - val_factorized_top_k/top_10_categorical_accuracy: 4.3898e-04 - val_factorized_top_k/top_50_categorical_accuracy: 0.0035 - val_factorized_top_k/top_100_categorical_accuracy: 0.1528 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Train accuracy: 0.5244289636611938\n",
      "Validation accuracy: 0.15276558697223663\n",
      "552/552 [==============================] - 155s 282ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 8.4949e-05 - factorized_top_k/top_10_categorical_accuracy: 1.6990e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0017 - factorized_top_k/top_100_categorical_accuracy: 0.1596 - loss: 4.8512 - regularization_loss: 0.0000e+00 - total_loss: 4.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 8.494853682350367e-05,\n",
       " 0.00016989707364700735,\n",
       " 0.0017272868426516652,\n",
       " 0.1595899760723114]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "model_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['body'],\n",
    "                                      feature_dims=[64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[],\n",
    "                                      compute_metrics=True)\n",
    "model_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "one_layer_history = model_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "model_one_layer.compute_metrics = True\n",
    "text_deep_metrics = model_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "text_deep_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese network trained with item tags text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 296s 174ms/step - factorized_top_k/top_1_categorical_accuracy: 0.7071 - factorized_top_k/top_5_categorical_accuracy: 0.7391 - factorized_top_k/top_10_categorical_accuracy: 0.7437 - factorized_top_k/top_50_categorical_accuracy: 0.7478 - factorized_top_k/top_100_categorical_accuracy: 0.7514 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.1431 - val_factorized_top_k/top_5_categorical_accuracy: 0.1450 - val_factorized_top_k/top_10_categorical_accuracy: 0.1528 - val_factorized_top_k/top_50_categorical_accuracy: 0.1528 - val_factorized_top_k/top_100_categorical_accuracy: 0.1528 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 308s 181ms/step - factorized_top_k/top_1_categorical_accuracy: 0.4259 - factorized_top_k/top_5_categorical_accuracy: 0.4719 - factorized_top_k/top_10_categorical_accuracy: 0.4824 - factorized_top_k/top_50_categorical_accuracy: 0.4889 - factorized_top_k/top_100_categorical_accuracy: 0.4922 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 315s 185ms/step - factorized_top_k/top_1_categorical_accuracy: 0.4553 - factorized_top_k/top_5_categorical_accuracy: 0.4925 - factorized_top_k/top_10_categorical_accuracy: 0.5000 - factorized_top_k/top_50_categorical_accuracy: 0.5078 - factorized_top_k/top_100_categorical_accuracy: 0.5125 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.9580 - val_factorized_top_k/top_5_categorical_accuracy: 0.9767 - val_factorized_top_k/top_10_categorical_accuracy: 0.9821 - val_factorized_top_k/top_50_categorical_accuracy: 0.9845 - val_factorized_top_k/top_100_categorical_accuracy: 0.9848 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Train accuracy: 0.5124850869178772\n",
      "Validation accuracy: 0.9847819805145264\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-342-4d30ae23bc0c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m \u001B[0mtags_deep_metrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel_one_layer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mholdout_logs_tf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcache\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m \u001B[0mtags_deep_metrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    106\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m     \u001B[0;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001B[0m\n\u001B[1;32m   1333\u001B[0m     \u001B[0m_keras_api_gauge\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_cell\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'evaluate'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1334\u001B[0m     \u001B[0mversion_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisallow_legacy_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Model'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'evaluate'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1335\u001B[0;31m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_assert_compile_was_called\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1336\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_call_args\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'evaluate'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1337\u001B[0m     \u001B[0m_disallow_inside_tf_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'evaluate'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_assert_compile_was_called\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   2567\u001B[0m     \u001B[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2568\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_compiled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2569\u001B[0;31m       raise RuntimeError('You must compile your model before '\n\u001B[0m\u001B[1;32m   2570\u001B[0m                          \u001B[0;34m'training/testing. '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2571\u001B[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001B[0;31mRuntimeError\u001B[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "tags_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['tags'],\n",
    "                                      feature_dims=[64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "tags_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "one_layer_history = tags_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "tags_deep_metrics = model_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "tags_deep_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552/552 [==============================] - 89s 161ms/step - factorized_top_k/top_1_categorical_accuracy: 0.9632 - factorized_top_k/top_5_categorical_accuracy: 0.9808 - factorized_top_k/top_10_categorical_accuracy: 0.9857 - factorized_top_k/top_50_categorical_accuracy: 0.9872 - factorized_top_k/top_100_categorical_accuracy: 0.9876 - loss: 4.8512 - regularization_loss: 0.0000e+00 - total_loss: 4.8512\n"
     ]
    }
   ],
   "source": [
    "tags_deep_metrics = tags_one_layer.evaluate(holdout_logs_tf.batch(128).cache())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese network trained with item tags text and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 723s 424ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0140 - factorized_top_k/top_5_categorical_accuracy: 0.0587 - factorized_top_k/top_10_categorical_accuracy: 0.0695 - factorized_top_k/top_50_categorical_accuracy: 0.0869 - factorized_top_k/top_100_categorical_accuracy: 0.0950 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.0088 - val_factorized_top_k/top_5_categorical_accuracy: 0.3333 - val_factorized_top_k/top_10_categorical_accuracy: 0.4036 - val_factorized_top_k/top_50_categorical_accuracy: 0.6738 - val_factorized_top_k/top_100_categorical_accuracy: 0.9617 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 653s 383ms/step - factorized_top_k/top_1_categorical_accuracy: 0.6046 - factorized_top_k/top_5_categorical_accuracy: 0.6613 - factorized_top_k/top_10_categorical_accuracy: 0.6792 - factorized_top_k/top_50_categorical_accuracy: 0.7110 - factorized_top_k/top_100_categorical_accuracy: 0.7263 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 5.8531e-04 - val_factorized_top_k/top_5_categorical_accuracy: 0.0438 - val_factorized_top_k/top_10_categorical_accuracy: 0.0697 - val_factorized_top_k/top_50_categorical_accuracy: 0.1254 - val_factorized_top_k/top_100_categorical_accuracy: 0.1403 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 625s 367ms/step - factorized_top_k/top_1_categorical_accuracy: 0.4435 - factorized_top_k/top_5_categorical_accuracy: 0.4908 - factorized_top_k/top_10_categorical_accuracy: 0.5078 - factorized_top_k/top_50_categorical_accuracy: 0.5386 - factorized_top_k/top_100_categorical_accuracy: 0.5538 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 5.8531e-04 - val_factorized_top_k/top_10_categorical_accuracy: 5.8531e-04 - val_factorized_top_k/top_50_categorical_accuracy: 0.0020 - val_factorized_top_k/top_100_categorical_accuracy: 0.0023 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Train accuracy: 0.5538436770439148\n",
      "Validation accuracy: 0.0023412350565195084\n",
      "552/552 [==============================] - 200s 362ms/step - factorized_top_k/top_1_categorical_accuracy: 4.2474e-05 - factorized_top_k/top_5_categorical_accuracy: 3.9643e-04 - factorized_top_k/top_10_categorical_accuracy: 3.9643e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0017 - factorized_top_k/top_100_categorical_accuracy: 0.0021 - loss: 4.8512 - regularization_loss: 0.0000e+00 - total_loss: 4.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.2474268411751837e-05,\n",
       " 0.0003964265051763505,\n",
       " 0.0003964265051763505,\n",
       " 0.0016564964316785336,\n",
       " 0.002067080931738019]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "tags_text_siamese = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['tags', 'body'],\n",
    "                                      feature_dims=[64, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "tags_text_siamese.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "tags_text_history = tags_text_siamese.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {tags_text_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {tags_text_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "tags_text_metrics = tags_text_siamese.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "tags_text_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Siamese network trained with item tags text and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 746s 438ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3441 - factorized_top_k/top_5_categorical_accuracy: 0.6136 - factorized_top_k/top_10_categorical_accuracy: 0.6474 - factorized_top_k/top_50_categorical_accuracy: 0.6939 - factorized_top_k/top_100_categorical_accuracy: 0.7140 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.0950 - val_factorized_top_k/top_5_categorical_accuracy: 0.9800 - val_factorized_top_k/top_10_categorical_accuracy: 0.9807 - val_factorized_top_k/top_50_categorical_accuracy: 0.9846 - val_factorized_top_k/top_100_categorical_accuracy: 0.9849 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 690s 405ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2354 - factorized_top_k/top_5_categorical_accuracy: 0.4494 - factorized_top_k/top_10_categorical_accuracy: 0.4717 - factorized_top_k/top_50_categorical_accuracy: 0.5028 - factorized_top_k/top_100_categorical_accuracy: 0.5151 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.3390 - val_factorized_top_k/top_5_categorical_accuracy: 0.9842 - val_factorized_top_k/top_10_categorical_accuracy: 0.9842 - val_factorized_top_k/top_50_categorical_accuracy: 0.9842 - val_factorized_top_k/top_100_categorical_accuracy: 0.9842 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 647s 380ms/step - factorized_top_k/top_1_categorical_accuracy: 0.3221 - factorized_top_k/top_5_categorical_accuracy: 0.5675 - factorized_top_k/top_10_categorical_accuracy: 0.5895 - factorized_top_k/top_50_categorical_accuracy: 0.6204 - factorized_top_k/top_100_categorical_accuracy: 0.6360 - loss: 4.8505 - regularization_loss: 0.0000e+00 - total_loss: 4.8505 - val_factorized_top_k/top_1_categorical_accuracy: 0.0097 - val_factorized_top_k/top_5_categorical_accuracy: 0.0209 - val_factorized_top_k/top_10_categorical_accuracy: 0.0209 - val_factorized_top_k/top_50_categorical_accuracy: 0.0209 - val_factorized_top_k/top_100_categorical_accuracy: 0.0209 - val_loss: 3.9120 - val_regularization_loss: 0.0000e+00 - val_total_loss: 3.9120\n",
      "Train accuracy: 0.6360425353050232\n",
      "Validation accuracy: 0.02092478796839714\n",
      "552/552 [==============================] - 200s 362ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0079 - factorized_top_k/top_5_categorical_accuracy: 0.0169 - factorized_top_k/top_10_categorical_accuracy: 0.0169 - factorized_top_k/top_50_categorical_accuracy: 0.0169 - factorized_top_k/top_100_categorical_accuracy: 0.0169 - loss: 4.8512 - regularization_loss: 0.0000e+00 - total_loss: 4.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00788605585694313,\n",
       " 0.01687644235789776,\n",
       " 0.016890600323677063,\n",
       " 0.01694723218679428,\n",
       " 0.01694723218679428]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "tags_body_deep = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['tags', 'body'],\n",
    "                                      feature_dims=[64, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[96])\n",
    "tags_body_deep.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "tags_body_deep_metrics = tags_body_deep.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {tags_body_deep_metrics.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {tags_body_deep_metrics.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "tags_body_deep_metrics = tags_body_deep.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "tags_body_deep_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Siamese network trained with item category and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 657s 386ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1241 - factorized_top_k/top_5_categorical_accuracy: 0.1245 - factorized_top_k/top_10_categorical_accuracy: 0.1245 - factorized_top_k/top_50_categorical_accuracy: 0.1353 - factorized_top_k/top_100_categorical_accuracy: 0.1606 - loss: 8.1411 - regularization_loss: 0.0000e+00 - total_loss: 8.1411 - val_factorized_top_k/top_1_categorical_accuracy: 0.1260 - val_factorized_top_k/top_5_categorical_accuracy: 0.1286 - val_factorized_top_k/top_10_categorical_accuracy: 0.1313 - val_factorized_top_k/top_50_categorical_accuracy: 0.1727 - val_factorized_top_k/top_100_categorical_accuracy: 0.1986 - val_loss: 8.5321 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.5321\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 572s 335ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1220 - factorized_top_k/top_5_categorical_accuracy: 0.1220 - factorized_top_k/top_10_categorical_accuracy: 0.1220 - factorized_top_k/top_50_categorical_accuracy: 0.1320 - factorized_top_k/top_100_categorical_accuracy: 0.1685 - loss: 8.7499 - regularization_loss: 0.0000e+00 - total_loss: 8.7499 - val_factorized_top_k/top_1_categorical_accuracy: 0.2328 - val_factorized_top_k/top_5_categorical_accuracy: 0.2340 - val_factorized_top_k/top_10_categorical_accuracy: 0.2349 - val_factorized_top_k/top_50_categorical_accuracy: 0.2558 - val_factorized_top_k/top_100_categorical_accuracy: 0.2821 - val_loss: 8.4556 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.4556\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 568s 334ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1162 - factorized_top_k/top_5_categorical_accuracy: 0.1162 - factorized_top_k/top_10_categorical_accuracy: 0.1162 - factorized_top_k/top_50_categorical_accuracy: 0.1218 - factorized_top_k/top_100_categorical_accuracy: 0.1508 - loss: 8.7714 - regularization_loss: 0.0000e+00 - total_loss: 8.7714 - val_factorized_top_k/top_1_categorical_accuracy: 0.1566 - val_factorized_top_k/top_5_categorical_accuracy: 0.2141 - val_factorized_top_k/top_10_categorical_accuracy: 0.2157 - val_factorized_top_k/top_50_categorical_accuracy: 0.2531 - val_factorized_top_k/top_100_categorical_accuracy: 0.2823 - val_loss: 8.5340 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.5340\n",
      "Train accuracy: 0.1508301943540573\n",
      "Validation accuracy: 0.28226515650749207\n",
      "552/552 [==============================] - 171s 310ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1338 - factorized_top_k/top_5_categorical_accuracy: 0.2114 - factorized_top_k/top_10_categorical_accuracy: 0.2121 - factorized_top_k/top_50_categorical_accuracy: 0.2504 - factorized_top_k/top_100_categorical_accuracy: 0.2808 - loss: 7.5441 - regularization_loss: 0.0000e+00 - total_loss: 7.5441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13383641839027405,\n",
       " 0.21135196089744568,\n",
       " 0.21207401156425476,\n",
       " 0.25039997696876526,\n",
       " 0.28076907992362976]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "tags_body_deep = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['category', 'body'],\n",
    "                                      feature_dims=[64, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[96])\n",
    "tags_body_deep.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "tags_body_deep_metrics = tags_body_deep.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {tags_body_deep_metrics.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {tags_body_deep_metrics.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "tags_body_deep_metrics = tags_body_deep.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "tags_body_deep_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Siamese network trained with item category and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 604s 355ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1008 - factorized_top_k/top_5_categorical_accuracy: 0.1013 - factorized_top_k/top_10_categorical_accuracy: 0.1015 - factorized_top_k/top_50_categorical_accuracy: 0.1130 - factorized_top_k/top_100_categorical_accuracy: 0.1380 - loss: 8.6451 - regularization_loss: 0.0000e+00 - total_loss: 8.6451 - val_factorized_top_k/top_1_categorical_accuracy: 0.2182 - val_factorized_top_k/top_5_categorical_accuracy: 0.2192 - val_factorized_top_k/top_10_categorical_accuracy: 0.2193 - val_factorized_top_k/top_50_categorical_accuracy: 0.2220 - val_factorized_top_k/top_100_categorical_accuracy: 0.2450 - val_loss: 7.4189 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4189\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 526s 309ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1016 - factorized_top_k/top_5_categorical_accuracy: 0.1020 - factorized_top_k/top_10_categorical_accuracy: 0.1022 - factorized_top_k/top_50_categorical_accuracy: 0.1128 - factorized_top_k/top_100_categorical_accuracy: 0.1396 - loss: 8.8262 - regularization_loss: 0.0000e+00 - total_loss: 8.8262 - val_factorized_top_k/top_1_categorical_accuracy: 0.0764 - val_factorized_top_k/top_5_categorical_accuracy: 0.0764 - val_factorized_top_k/top_10_categorical_accuracy: 0.0765 - val_factorized_top_k/top_50_categorical_accuracy: 0.0840 - val_factorized_top_k/top_100_categorical_accuracy: 0.1001 - val_loss: 7.4076 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4076\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 526s 309ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0993 - factorized_top_k/top_5_categorical_accuracy: 0.0996 - factorized_top_k/top_10_categorical_accuracy: 0.0998 - factorized_top_k/top_50_categorical_accuracy: 0.1103 - factorized_top_k/top_100_categorical_accuracy: 0.1357 - loss: 8.8856 - regularization_loss: 0.0000e+00 - total_loss: 8.8856 - val_factorized_top_k/top_1_categorical_accuracy: 0.0944 - val_factorized_top_k/top_5_categorical_accuracy: 0.0950 - val_factorized_top_k/top_10_categorical_accuracy: 0.0950 - val_factorized_top_k/top_50_categorical_accuracy: 0.1011 - val_factorized_top_k/top_100_categorical_accuracy: 0.1200 - val_loss: 7.8349 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.8349\n",
      "Train accuracy: 0.13572148978710175\n",
      "Validation accuracy: 0.11998829245567322\n",
      "552/552 [==============================] - 172s 312ms/step - factorized_top_k/top_1_categorical_accuracy: 0.1161 - factorized_top_k/top_5_categorical_accuracy: 0.1166 - factorized_top_k/top_10_categorical_accuracy: 0.1166 - factorized_top_k/top_50_categorical_accuracy: 0.1214 - factorized_top_k/top_100_categorical_accuracy: 0.1405 - loss: 8.3816 - regularization_loss: 0.0000e+00 - total_loss: 8.3816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11613880842924118,\n",
       " 0.11659186333417892,\n",
       " 0.11659186333417892,\n",
       " 0.12143392860889435,\n",
       " 0.1405048817396164]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "tags_body_deep = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['category', 'body'],\n",
    "                                      feature_dims=[64, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "tags_body_deep.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "tags_body_deep_metrics = tags_body_deep.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {tags_body_deep_metrics.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {tags_body_deep_metrics.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "tags_body_deep_metrics = tags_body_deep.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "tags_body_deep_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure CF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 139s 82ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0920 - factorized_top_k/top_10_categorical_accuracy: 0.1408 - factorized_top_k/top_50_categorical_accuracy: 0.2360 - factorized_top_k/top_100_categorical_accuracy: 0.2791 - loss: 8.9186 - regularization_loss: 0.0000e+00 - total_loss: 8.9186 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.1223 - val_factorized_top_k/top_10_categorical_accuracy: 0.1803 - val_factorized_top_k/top_50_categorical_accuracy: 0.2479 - val_factorized_top_k/top_100_categorical_accuracy: 0.2944 - val_loss: 6.2466 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.2466\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 140s 82ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.1180 - factorized_top_k/top_10_categorical_accuracy: 0.1679 - factorized_top_k/top_50_categorical_accuracy: 0.2804 - factorized_top_k/top_100_categorical_accuracy: 0.3321 - loss: 9.0030 - regularization_loss: 0.0000e+00 - total_loss: 9.0030 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.1506 - val_factorized_top_k/top_10_categorical_accuracy: 0.1891 - val_factorized_top_k/top_50_categorical_accuracy: 0.2789 - val_factorized_top_k/top_100_categorical_accuracy: 0.3017 - val_loss: 6.7166 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.7166\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 141s 83ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.1231 - factorized_top_k/top_10_categorical_accuracy: 0.1653 - factorized_top_k/top_50_categorical_accuracy: 0.2845 - factorized_top_k/top_100_categorical_accuracy: 0.3393 - loss: 9.0097 - regularization_loss: 0.0000e+00 - total_loss: 9.0097 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.1768 - val_factorized_top_k/top_10_categorical_accuracy: 0.2180 - val_factorized_top_k/top_50_categorical_accuracy: 0.2826 - val_factorized_top_k/top_100_categorical_accuracy: 0.3130 - val_loss: 6.3418 - val_regularization_loss: 0.0000e+00 - val_total_loss: 6.3418\n",
      "Train accuracy: 0.5124850869178772\n",
      "Validation accuracy: 0.9847819805145264\n",
      "552/552 [==============================] - 44s 80ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.1478 - factorized_top_k/top_10_categorical_accuracy: 0.1754 - factorized_top_k/top_50_categorical_accuracy: 0.2313 - factorized_top_k/top_100_categorical_accuracy: 0.2578 - loss: 8.7640 - regularization_loss: 0.0000e+00 - total_loss: 8.7640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.1478104442358017,\n",
       " 0.17544704675674438,\n",
       " 0.23131486773490906,\n",
       " 0.2577621638774872]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "cf_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['item_id'],\n",
    "                                      feature_dims=[100],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "cf_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "cf_one_layer_history = cf_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "id_metrics = cf_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "id_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CF + body + category embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 635s 373ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0179 - factorized_top_k/top_5_categorical_accuracy: 0.1033 - factorized_top_k/top_10_categorical_accuracy: 0.1400 - factorized_top_k/top_50_categorical_accuracy: 0.2147 - factorized_top_k/top_100_categorical_accuracy: 0.2598 - loss: 8.1931 - regularization_loss: 0.0000e+00 - total_loss: 8.1931 - val_factorized_top_k/top_1_categorical_accuracy: 0.0143 - val_factorized_top_k/top_5_categorical_accuracy: 0.0896 - val_factorized_top_k/top_10_categorical_accuracy: 0.1346 - val_factorized_top_k/top_50_categorical_accuracy: 0.1858 - val_factorized_top_k/top_100_categorical_accuracy: 0.2609 - val_loss: 8.7385 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.7385\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 561s 329ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0172 - factorized_top_k/top_5_categorical_accuracy: 0.1251 - factorized_top_k/top_10_categorical_accuracy: 0.1732 - factorized_top_k/top_50_categorical_accuracy: 0.2499 - factorized_top_k/top_100_categorical_accuracy: 0.3018 - loss: 9.1053 - regularization_loss: 0.0000e+00 - total_loss: 9.1053 - val_factorized_top_k/top_1_categorical_accuracy: 0.0111 - val_factorized_top_k/top_5_categorical_accuracy: 0.1036 - val_factorized_top_k/top_10_categorical_accuracy: 0.1354 - val_factorized_top_k/top_50_categorical_accuracy: 0.2016 - val_factorized_top_k/top_100_categorical_accuracy: 0.2820 - val_loss: 8.6998 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.6998\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 600s 352ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0172 - factorized_top_k/top_5_categorical_accuracy: 0.1302 - factorized_top_k/top_10_categorical_accuracy: 0.1836 - factorized_top_k/top_50_categorical_accuracy: 0.2606 - factorized_top_k/top_100_categorical_accuracy: 0.3112 - loss: 9.1563 - regularization_loss: 0.0000e+00 - total_loss: 9.1563 - val_factorized_top_k/top_1_categorical_accuracy: 0.0195 - val_factorized_top_k/top_5_categorical_accuracy: 0.1068 - val_factorized_top_k/top_10_categorical_accuracy: 0.1428 - val_factorized_top_k/top_50_categorical_accuracy: 0.2243 - val_factorized_top_k/top_100_categorical_accuracy: 0.2903 - val_loss: 8.4535 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.4535\n",
      "Train accuracy: 0.5124850869178772\n",
      "Validation accuracy: 0.9847819805145264\n",
      "552/552 [==============================] - 220s 398ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0192 - factorized_top_k/top_5_categorical_accuracy: 0.0868 - factorized_top_k/top_10_categorical_accuracy: 0.1155 - factorized_top_k/top_50_categorical_accuracy: 0.1949 - factorized_top_k/top_100_categorical_accuracy: 0.2597 - loss: 8.7710 - regularization_loss: 0.0000e+00 - total_loss: 8.7710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.019240843132138252,\n",
       " 0.0867890864610672,\n",
       " 0.11547337472438812,\n",
       " 0.19494272768497467,\n",
       " 0.25967350602149963]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "cf_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['item_id', 'body', 'category'],\n",
    "                                      feature_dims=[64, 64, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[96])\n",
    "cf_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "cf_one_layer_history = cf_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "id_metrics = cf_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "id_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CF + body  embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 600s 352ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0115 - factorized_top_k/top_5_categorical_accuracy: 0.1137 - factorized_top_k/top_10_categorical_accuracy: 0.1675 - factorized_top_k/top_50_categorical_accuracy: 0.2580 - factorized_top_k/top_100_categorical_accuracy: 0.2865 - loss: 5.2211 - regularization_loss: 0.0000e+00 - total_loss: 5.2211 - val_factorized_top_k/top_1_categorical_accuracy: 0.0120 - val_factorized_top_k/top_5_categorical_accuracy: 0.1999 - val_factorized_top_k/top_10_categorical_accuracy: 0.2934 - val_factorized_top_k/top_50_categorical_accuracy: 0.4277 - val_factorized_top_k/top_100_categorical_accuracy: 0.4447 - val_loss: 4.9520 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.9520\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 507s 297ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0243 - factorized_top_k/top_5_categorical_accuracy: 0.2088 - factorized_top_k/top_10_categorical_accuracy: 0.3477 - factorized_top_k/top_50_categorical_accuracy: 0.6227 - factorized_top_k/top_100_categorical_accuracy: 0.6471 - loss: 8.7887 - regularization_loss: 0.0000e+00 - total_loss: 8.7887 - val_factorized_top_k/top_1_categorical_accuracy: 0.0268 - val_factorized_top_k/top_5_categorical_accuracy: 0.2043 - val_factorized_top_k/top_10_categorical_accuracy: 0.3123 - val_factorized_top_k/top_50_categorical_accuracy: 0.4761 - val_factorized_top_k/top_100_categorical_accuracy: 0.5085 - val_loss: 4.5088 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.5088\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 510s 299ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0167 - factorized_top_k/top_5_categorical_accuracy: 0.2085 - factorized_top_k/top_10_categorical_accuracy: 0.3637 - factorized_top_k/top_50_categorical_accuracy: 0.6269 - factorized_top_k/top_100_categorical_accuracy: 0.6584 - loss: 8.7100 - regularization_loss: 0.0000e+00 - total_loss: 8.7100 - val_factorized_top_k/top_1_categorical_accuracy: 0.0266 - val_factorized_top_k/top_5_categorical_accuracy: 0.2062 - val_factorized_top_k/top_10_categorical_accuracy: 0.3107 - val_factorized_top_k/top_50_categorical_accuracy: 0.4729 - val_factorized_top_k/top_100_categorical_accuracy: 0.5100 - val_loss: 4.5490 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.5490\n",
      "Train accuracy: 0.5124850869178772\n",
      "Validation accuracy: 0.9847819805145264\n",
      "552/552 [==============================] - 178s 322ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0202 - factorized_top_k/top_5_categorical_accuracy: 0.1514 - factorized_top_k/top_10_categorical_accuracy: 0.2336 - factorized_top_k/top_50_categorical_accuracy: 0.3986 - factorized_top_k/top_100_categorical_accuracy: 0.4356 - loss: 6.1705 - regularization_loss: 0.0000e+00 - total_loss: 6.1705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0201894361525774,\n",
       " 0.15136413276195526,\n",
       " 0.23360846936702728,\n",
       " 0.3986351490020752,\n",
       " 0.43557360768318176]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "cf_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['item_id', 'body'],\n",
    "                                      feature_dims=[100, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[100])\n",
    "cf_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "cf_one_layer_history = cf_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "id_metrics = cf_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "id_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow_recommenders/models/base.py:76 train_step\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:513 apply_gradients\n        grads_and_vars = _filter_grads(grads_and_vars)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1271 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['counter:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-310-4b9bac129cf2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mvalidation_freq\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m     verbose=1)\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    106\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m     \u001B[0;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1096\u001B[0m                 batch_size=batch_size):\n\u001B[1;32m   1097\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1098\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1099\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1100\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    778\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    821\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    822\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 823\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    824\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    825\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    695\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m    696\u001B[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0;32m--> 697\u001B[0;31m             *args, **kwds))\n\u001B[0m\u001B[1;32m    698\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    699\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minvalid_creator_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0munused_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munused_kwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2853\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2854\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2855\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2856\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2857\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3212\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3213\u001B[0;31m       \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3214\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3215\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3073\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3074\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3075\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3076\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3077\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    985\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 986\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    987\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    598\u001B[0m         \u001B[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    599\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 600\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    601\u001B[0m     \u001B[0mweak_wrapped_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mref\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    971\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    972\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 973\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    974\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    975\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow_recommenders/models/base.py:76 train_step\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:513 apply_gradients\n        grads_and_vars = _filter_grads(grads_and_vars)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1271 _filter_grads\n        ([v.name for _, v in grads_and_vars],))\n\n    ValueError: No gradients provided for any variable: ['counter:0'].\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "#model_link = 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'\n",
    "#text_model = {\"format\": \"text\", \"link\": model_link}\n",
    "recsys2_im = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['image_embedding'],\n",
    "                                      feature_dims=[None],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "\n",
    "recsys2_im.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "recsys2_im.fit(    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "recsys2_im_metrics = recsys2_im.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "\n",
    "recsys2_im_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 600s 352ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0115 - factorized_top_k/top_5_categorical_accuracy: 0.1137 - factorized_top_k/top_10_categorical_accuracy: 0.1675 - factorized_top_k/top_50_categorical_accuracy: 0.2580 - factorized_top_k/top_100_categorical_accuracy: 0.2865 - loss: 5.2211 - regularization_loss: 0.0000e+00 - total_loss: 5.2211 - val_factorized_top_k/top_1_categorical_accuracy: 0.0120 - val_factorized_top_k/top_5_categorical_accuracy: 0.1999 - val_factorized_top_k/top_10_categorical_accuracy: 0.2934 - val_factorized_top_k/top_50_categorical_accuracy: 0.4277 - val_factorized_top_k/top_100_categorical_accuracy: 0.4447 - val_loss: 4.9520 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.9520\n",
      "Epoch 2/3\n",
      "1704/1704 [==============================] - 507s 297ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0243 - factorized_top_k/top_5_categorical_accuracy: 0.2088 - factorized_top_k/top_10_categorical_accuracy: 0.3477 - factorized_top_k/top_50_categorical_accuracy: 0.6227 - factorized_top_k/top_100_categorical_accuracy: 0.6471 - loss: 8.7887 - regularization_loss: 0.0000e+00 - total_loss: 8.7887 - val_factorized_top_k/top_1_categorical_accuracy: 0.0268 - val_factorized_top_k/top_5_categorical_accuracy: 0.2043 - val_factorized_top_k/top_10_categorical_accuracy: 0.3123 - val_factorized_top_k/top_50_categorical_accuracy: 0.4761 - val_factorized_top_k/top_100_categorical_accuracy: 0.5085 - val_loss: 4.5088 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.5088\n",
      "Epoch 3/3\n",
      "1704/1704 [==============================] - 510s 299ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0167 - factorized_top_k/top_5_categorical_accuracy: 0.2085 - factorized_top_k/top_10_categorical_accuracy: 0.3637 - factorized_top_k/top_50_categorical_accuracy: 0.6269 - factorized_top_k/top_100_categorical_accuracy: 0.6584 - loss: 8.7100 - regularization_loss: 0.0000e+00 - total_loss: 8.7100 - val_factorized_top_k/top_1_categorical_accuracy: 0.0266 - val_factorized_top_k/top_5_categorical_accuracy: 0.2062 - val_factorized_top_k/top_10_categorical_accuracy: 0.3107 - val_factorized_top_k/top_50_categorical_accuracy: 0.4729 - val_factorized_top_k/top_100_categorical_accuracy: 0.5100 - val_loss: 4.5490 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.5490\n",
      "Train accuracy: 0.5124850869178772\n",
      "Validation accuracy: 0.9847819805145264\n",
      "552/552 [==============================] - 178s 322ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0202 - factorized_top_k/top_5_categorical_accuracy: 0.1514 - factorized_top_k/top_10_categorical_accuracy: 0.2336 - factorized_top_k/top_50_categorical_accuracy: 0.3986 - factorized_top_k/top_100_categorical_accuracy: 0.4356 - loss: 6.1705 - regularization_loss: 0.0000e+00 - total_loss: 6.1705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0201894361525774,\n",
       " 0.15136413276195526,\n",
       " 0.23360846936702728,\n",
       " 0.3986351490020752,\n",
       " 0.43557360768318176]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.batch(128).cache()\n",
    "cached_test = sfv_test.batch(128).cache()\n",
    "cf_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['item_id', 'body'],\n",
    "                                      feature_dims=[100, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[100])\n",
    "cf_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "cf_one_layer_history = cf_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "id_metrics = cf_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "id_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0039 - factorized_top_k/top_100_categorical_accuracy: 0.0039 - loss: 4.8954 - regularization_loss: 0.0000e+00 - total_loss: 4.8954        WARNING:tensorflow:Model was constructed with shape (None,) for input Tensor(\"item_id_string_lookup_layer_input_6:0\", shape=(None,), dtype=string), but it was called on an input with incompatible shape ().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None,) for input Tensor(\"item_id_string_lookup_layer_input_6:0\", shape=(None,), dtype=string), but it was called on an input with incompatible shape ().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None,) for input Tensor(\"body_text_vectorisation_layer_input_5:0\", shape=(None,), dtype=string), but it was called on an input with incompatible shape ().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None,) for input Tensor(\"body_text_vectorisation_layer_input_5:0\", shape=(None,), dtype=string), but it was called on an input with incompatible shape ().\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 test_function  *\n        return step_function(self, iterator)\n    <ipython-input-6-e48051f929fe>:104 call  *\n        feature_embeddings.append(self.body_embedding(body))\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer body_global_averaging_pooling_layer is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 64]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-75-a91b72151190>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0mvalidation_freq\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m     verbose=1)\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;31m#    callbacks=[tensorboard_callback])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    106\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m     \u001B[0;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1131\u001B[0m               \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m               \u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1133\u001B[0;31m               return_dict=True)\n\u001B[0m\u001B[1;32m   1134\u001B[0m           \u001B[0mval_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'val_'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mval\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mval_logs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m           \u001B[0mepoch_logs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_logs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    106\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m     \u001B[0;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001B[0m\n\u001B[1;32m   1377\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'TraceContext'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgraph_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep_num\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1378\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_test_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1379\u001B[0;31m               \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1380\u001B[0m               \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1381\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    778\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    779\u001B[0m         \u001B[0mcompiler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"nonXla\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 780\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    781\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    782\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    821\u001B[0m       \u001B[0;31m# This is the first call of __call__, so we have to initialize.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    822\u001B[0m       \u001B[0minitializers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 823\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_initialize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_initializers_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    824\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    825\u001B[0m       \u001B[0;31m# At this point we know that the initialization is complete (or less\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    695\u001B[0m     self._concrete_stateful_fn = (\n\u001B[1;32m    696\u001B[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001B[0;32m--> 697\u001B[0;31m             *args, **kwds))\n\u001B[0m\u001B[1;32m    698\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    699\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0minvalid_creator_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0munused_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munused_kwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_get_concrete_function_internal_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2853\u001B[0m       \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2854\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2855\u001B[0;31m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2856\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2857\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_maybe_define_function\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   3211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3212\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmissed\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcall_context_key\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3213\u001B[0;31m       \u001B[0mgraph_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_graph_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3214\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_cache\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprimary\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcache_key\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3215\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_create_graph_function\u001B[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m   3073\u001B[0m             \u001B[0marg_names\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0marg_names\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3074\u001B[0m             \u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moverride_flat_arg_shapes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3075\u001B[0;31m             capture_by_value=self._capture_by_value),\n\u001B[0m\u001B[1;32m   3076\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_function_attributes\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3077\u001B[0m         \u001B[0mfunction_spec\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction_spec\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001B[0m\n\u001B[1;32m    984\u001B[0m         \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moriginal_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf_decorator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munwrap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpython_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    985\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 986\u001B[0;31m       \u001B[0mfunc_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpython_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mfunc_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfunc_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    987\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    988\u001B[0m       \u001B[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36mwrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    598\u001B[0m         \u001B[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    599\u001B[0m         \u001B[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 600\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mweak_wrapped_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__wrapped__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    601\u001B[0m     \u001B[0mweak_wrapped_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweakref\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mref\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwrapped_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    602\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    971\u001B[0m           \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint:disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    972\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"ag_error_metadata\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 973\u001B[0;31m               \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    974\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    975\u001B[0m               \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1224 test_function  *\n        return step_function(self, iterator)\n    <ipython-input-6-e48051f929fe>:104 call  *\n        feature_embeddings.append(self.body_embedding(body))\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /Users/mercef02/.virtualenvs/exploration-Tqzb7Mc2/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:180 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer body_global_averaging_pooling_layer is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 64]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "cached_train = sfv_train.take(256).batch(128).cache()\n",
    "cached_test = sfv_val.take(256).batch(128).cache()\n",
    "cf_one_layer = ItemSimilarityModel(test_candidate_ids=unique_item_ids,\n",
    "                                      features=['item_id', 'body'],\n",
    "                                      feature_dims=[100, 64],\n",
    "                                      unique_item_ids=unique_item_ids,\n",
    "                                      item_body_lookup=body_lookup_table,\n",
    "                                      item_tags_lookup=tags_lookup_table,\n",
    "                                      item_category_lookup=category_lookup_table,\n",
    "                                      item_image_lookup=thumbnail_lookup_table,\n",
    "                                      image_embedding_lookup_table=im_embeddings_lookup,\n",
    "                                      layer_sizes=[])\n",
    "cf_one_layer.compile(optimizer=tf.keras.optimizers.Adagrad(lr))\n",
    "\n",
    "cf_one_layer_history = cf_one_layer.fit(\n",
    "    cached_train,\n",
    "    validation_data=sfv_val,\n",
    "    validation_freq=1,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1)\n",
    "#    callbacks=[tensorboard_callback])\n",
    "\n",
    "print(f'Train accuracy: {one_layer_history.history[\"factorized_top_k/top_100_categorical_accuracy\"][-1]}')   \n",
    "print(f'Validation accuracy: {one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"][-1]}')\n",
    "\n",
    "id_metrics = cf_one_layer.evaluate(holdout_logs_tf.batch(128).cache())\n",
    "id_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are the results sensible?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export embeddings into nearest neighbour index\n",
    "\n",
    "# Let's get the most paired items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_embeddings = get_dict_of_embeddings(trained_model, unique_item_ids)\n",
    "annoy_index, id_to_uri, uri_to_id = build_annoy_index(item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#query_uri = '/news/technology-53018000'\n",
    "#query_uri = '/sport/football/53805003'\n",
    "#query_uri = '/news/business-10665047'\n",
    "#query_uri = '/news/uk-england-hampshire-53838761'\n",
    "\n",
    "query_uri, groundtruth_uri = vc.index[1].split('_')\n",
    "print(f'query_uri = {query_uri}')\n",
    "print(f'groundtruth_uri = {groundtruth_uri}')\n",
    "\n",
    "rec_uris = generate_model_recs(query_uri, annoy_index, uri_to_id, id_to_uri, uri_to_embedding, es, _es_index, 20)\n",
    "print(f'LITMUS TEST: {groundtruth_uri in rec_uris}')\n",
    "print('-------------------')\n",
    "print('-------------------')\n",
    "\n",
    "for rec in rec_uris:\n",
    "    print_item(rec, es, _es_index)\n",
    "    print('-------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use brute-force search to set up retrieval using the trained representations.\n",
    "# index = tfrs.layers.ann.BruteForce(trained_model.item_model)\n",
    "# index.index(items_tf.batch(100).map(trained_model.item_model), items_tf)\n",
    "# # Get some recommendations.\n",
    "# query_uri = '/news/business-10665047'\n",
    "# query_uri = '129'\n",
    "# _, titles = index(np.array([query_uri]))\n",
    "# print(f\"Top 3 recommendations for item {query_uri}: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = request_asset_from_ares()\n",
    "a\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-recommender-embeddings",
   "language": "python",
   "name": "deep-recommender-embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}