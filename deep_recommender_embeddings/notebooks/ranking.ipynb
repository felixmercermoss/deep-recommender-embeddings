{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from annoy import AnnoyIndex\n",
    "import sys\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "from deep_recommender_embeddings.src.ares import request_asset_from_ares\n",
    "from deep_recommender_embeddings.src.elasticsearch_utils import get_es_instance, get_data_from_es, print_item\n",
    "from deep_recommender_embeddings.src.image_embeddings import generate_image_embeddings\n",
    "from deep_recommender_embeddings.src.models import ItemSimilarityModel, UserItemModel\n",
    "from deep_recommender_embeddings.src.plotting import plot_metric\n",
    "from deep_recommender_embeddings.src.tf_utils import get_tf_lookup_table_for_property, get_tf_lookup_for_dict\n",
    "from deep_recommender_embeddings.src.inference import get_dict_of_embeddings, build_annoy_index\n",
    "from deep_recommender_embeddings.src.io import export_embeddings_to_file\n",
    "from deep_recommender_embeddings.src.preprocessing import load_data, clean_data, filter_logs, get_pairs, \\\n",
    "    get_item_pairs_from_journeys, generate_model_recs, get_pairs_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load content data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_es_index = 'news_20210305c'\n",
    "_es_host = 'localhost'\n",
    "_es_port = '9200'\n",
    "es = get_es_instance(es_host=_es_host, es_port=_es_port)\n",
    "\n",
    "# This is the imaginary date that recommendations will be generated on\n",
    "prediction_time = \"2020-11-02T00:00:00\"\n",
    "\n",
    "# Business rules usually prevent recs being returned that are older than 90 days so we will only retrieve items\n",
    "# that were published within this time window\n",
    "max_age_days = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Grabbed 42732 items from elasticsearch\n"
     ]
    }
   ],
   "source": [
    "features = [\"combinedBodySummaryHeadline\", \"tagsText\", \"articleCategoryName\"]\n",
    "hits = get_data_from_es(es, features, 50000, 5000, prediction_time, max_age_days, _es_index)\n",
    "unique_item_ids = [hit['sort'][0] for hit in hits]\n",
    "print(f'Grabbed {len(unique_item_ids)} items from elasticsearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FIELD = 'event_start_datetime'\n",
    "USER_FIELD = 'audience_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/mercef02/Projects/datasets_models/news_uk_logs_20210304/00*' #'/Users/mercef02/Projects/datasets/sfv_user_week_compact/*.csv'\n",
    "logs = load_data(d_path=DATA_PATH, stop_after_n_files=1, date_field=DATE_FIELD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = clean_data(logs, [USER_FIELD, DATE_FIELD, 'url', 'geo_city_site_visited'], '/news/')\n",
    "min_date = pd.to_datetime('2021-03-04T00:00:00')\n",
    "max_date = pd.to_datetime('2021-03-04T11:59:59')\n",
    "min_mentions = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original interactions: 1685668\n",
      "Date filtered interactions: 670621\n",
      "Minimum mention filtered interactions  : 653335\n",
      "Interactions filtered for items existing in ES : 559809\n"
     ]
    }
   ],
   "source": [
    "train_logs = filter_logs(logs, min_date, max_date, min_mentions, unique_item_ids, DATE_FIELD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audience_id</th>\n",
       "      <th>event_start_datetime</th>\n",
       "      <th>geo_city_site_visited</th>\n",
       "      <th>uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lpucBML/6soz1U/TcHk93BCzL/Ki+P+q6RxwKDWN4fg=</td>\n",
       "      <td>2021-03-04 02:52:31</td>\n",
       "      <td>Southwark</td>\n",
       "      <td>/news/technology-56239242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sPYIdNHgYJ98Gpw96yDcQgsFpeQfC0EJpPaSpVscw34=</td>\n",
       "      <td>2021-03-04 01:52:28</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>/news/world-asia-55472446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3Lr5OzuexWD6m0bj08MikLbtjwGhj/Fc2gU3Z7tiSzY=</td>\n",
       "      <td>2021-03-04 00:35:18</td>\n",
       "      <td>Wakefield</td>\n",
       "      <td>/news/uk-56272104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>G5pAYXT347wHjlC4ONQYVdsMAwSFtl1ysjRud0XE2n8=</td>\n",
       "      <td>2021-03-04 00:50:39</td>\n",
       "      <td>Omagh</td>\n",
       "      <td>/news/uk-56267807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>rE3xy1mrmqGZ7P77YYs7y+e3/VqH+zu2Pp0Btu3Tp34=</td>\n",
       "      <td>2021-03-04 00:07:06</td>\n",
       "      <td>Stockton-on-tees</td>\n",
       "      <td>/news/business-56263581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      audience_id event_start_datetime  \\\n",
       "29   lpucBML/6soz1U/TcHk93BCzL/Ki+P+q6RxwKDWN4fg=  2021-03-04 02:52:31   \n",
       "39   sPYIdNHgYJ98Gpw96yDcQgsFpeQfC0EJpPaSpVscw34=  2021-03-04 01:52:28   \n",
       "158  3Lr5OzuexWD6m0bj08MikLbtjwGhj/Fc2gU3Z7tiSzY=  2021-03-04 00:35:18   \n",
       "159  G5pAYXT347wHjlC4ONQYVdsMAwSFtl1ysjRud0XE2n8=  2021-03-04 00:50:39   \n",
       "160  rE3xy1mrmqGZ7P77YYs7y+e3/VqH+zu2Pp0Btu3Tp34=  2021-03-04 00:07:06   \n",
       "\n",
       "    geo_city_site_visited                        uri  \n",
       "29              Southwark  /news/technology-56239242  \n",
       "39             Manchester  /news/world-asia-55472446  \n",
       "158             Wakefield          /news/uk-56272104  \n",
       "159                 Omagh          /news/uk-56267807  \n",
       "160      Stockton-on-tees    /news/business-56263581  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/news/uk-56278445', '/news/uk-56272104', '/news/health-55045639',\n",
       "       ..., '/news/health-56271627',\n",
       "       '/news/uk-england-northamptonshire-56274524', '/news/56238260'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(train_pairs['candidate_item'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mercef02/.local/share/virtualenvs/deep-recommender-embeddings-vIGdqmCw/lib/python3.8/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/Users/mercef02/.local/share/virtualenvs/deep-recommender-embeddings-vIGdqmCw/lib/python3.8/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pairs: 1119618\n"
     ]
    }
   ],
   "source": [
    "train_pairs_pos = train_logs[['geo_city_site_visited', 'uri']]\n",
    "train_pairs_pos.columns = ['user_location', 'candidate_item']\n",
    "train_pairs_pos.loc[:, 'user_rating'] = np.ones(shape=(len(train_pairs), 1))\n",
    "\n",
    "train_pairs_neg = train_pairs_pos.copy()\n",
    "train_pairs_neg.loc[:, 'candidate_item'] = np.random.permutation(train_pairs['candidate_item'].to_numpy())\n",
    "train_pairs_neg.loc[:, 'user_rating'] = np.zeros(shape=(len(train_pairs), 1))\n",
    "\n",
    "train_pairs = pd.concat([train_pairs_pos, train_pairs_neg], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total number of pairs: {len(train_pairs)}\")\n",
    "train_logs_tf = tf.data.Dataset.from_tensor_slices(dict(train_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559809"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pairs_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_vocab=np.array(train_logs.geo_city_site_visited.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>candidate_item</th>\n",
       "      <th>user_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Southwark</td>\n",
       "      <td>/news/technology-56239242</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Manchester</td>\n",
       "      <td>/news/world-asia-55472446</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Wakefield</td>\n",
       "      <td>/news/uk-56272104</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Omagh</td>\n",
       "      <td>/news/uk-56267807</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Stockton-on-tees</td>\n",
       "      <td>/news/business-56263581</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_location             candidate_item  user_rating\n",
       "29          Southwark  /news/technology-56239242          1.0\n",
       "39         Manchester  /news/world-asia-55472446          1.0\n",
       "158         Wakefield          /news/uk-56272104          1.0\n",
       "159             Omagh          /news/uk-56267807          1.0\n",
       "160  Stockton-on-tees    /news/business-56263581          1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.initializers.initializers_v2 import VarianceScaling\n",
    "import uuid\n",
    "\n",
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, features=['location', 'item_id'], feature_dims=[32, 32], layer_sizes=[256, 64]):\n",
    "    super().__init__()\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        \n",
    "        if feature == 'location':\n",
    "            # Compute embeddings for users.\n",
    "            self.location_embeddings = tf.keras.Sequential([\n",
    "              tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=location_vocab, mask_token=None),\n",
    "              tf.keras.layers.Embedding(len(location_vocab) + 1, feature_dims[i])\n",
    "            ])\n",
    "        \n",
    "        if feature == 'item_id':\n",
    "            # Compute embeddings for items.\n",
    "            self.item_embeddings = tf.keras.Sequential([\n",
    "              tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_item_ids, mask_token=None),\n",
    "              tf.keras.layers.Embedding(len(unique_item_ids) + 1, feature_dims[i])\n",
    "            ])\n",
    "        \n",
    "        if feature == 'user_id':\n",
    "            # Compute embeddings for items.\n",
    "            self.user_embeddings = tf.keras.Sequential([\n",
    "              tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_item_ids, mask_token=None),\n",
    "              tf.keras.layers.Embedding(len(unique_item_ids) + 1, feature_dims[i])\n",
    "            ])            \n",
    "\n",
    "     # Then construct the layers.\n",
    "    self.ratings = tf.keras.Sequential(name='sequential_deep')\n",
    "    \n",
    "    # Compute predictions.\n",
    "    # Use the ReLU activation for all but the last layer.\n",
    "    for i, layer_size in enumerate(layer_sizes):\n",
    "        \n",
    "        # Batch normalization after the first layer\n",
    "        if i == 0:\n",
    "             self.ratings.add(tf.keras.layers.BatchNormalization())\n",
    "                \n",
    "        self.ratings.add(tf.keras.layers.Dense(layer_size,\n",
    "                                                    activation=\"relu\",\n",
    "                                                    kernel_initializer=VarianceScaling(),\n",
    "                                                    bias_initializer=VarianceScaling(),\n",
    "                                                    name=f\"dense_layer_{i + 1}_{str(uuid.uuid4())}\"))\n",
    "    # Make rating predictions in the final layer.\n",
    "    self.ratings.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_location, item_id = inputs\n",
    "\n",
    "    location_embedding = self.location_embeddings(user_location)\n",
    "    item_embedding = self.item_embeddings(item_id)\n",
    "\n",
    "    return self.ratings(tf.concat([location_embedding, item_embedding], axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reranker(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, features=['location', 'item_id'], feature_dims=[32, 32], layer_sizes=[256, 64]):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel(features=features, feature_dims=feature_dims, layer_sizes=layer_sizes)\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    rating_predictions = self.ranking_model(\n",
    "        (features[\"user_location\"], features[\"candidate_item\"]))\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=features[\"user_rating\"], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train pairs: 1097225\n",
      "Number of test pairs: 22392\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "training_shuffled = train_logs_tf.shuffle(buffer_size=100_000, seed=42, reshuffle_each_iteration=False)\n",
    "train_pc = 0.98\n",
    "test_pc = 0.02\n",
    "news_train = training_shuffled.take(np.floor(len(training_shuffled)*train_pc))\n",
    "news_val = training_shuffled.skip(np.floor(len(training_shuffled)*train_pc)).take(np.floor(len(training_shuffled)*test_pc))\n",
    "\n",
    "print(f'Number of train pairs: {len(news_train)}')\n",
    "print(f'Number of test pairs: {len(news_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "134/134 [==============================] - 11s 76ms/step - root_mean_squared_error: 0.3305 - loss: 0.1085 - regularization_loss: 0.0000e+00 - total_loss: 0.1085\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 4s 28ms/step - root_mean_squared_error: 0.3889 - loss: 0.1502 - regularization_loss: 0.0000e+00 - total_loss: 0.1502\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 4s 29ms/step - root_mean_squared_error: 0.4168 - loss: 0.1726 - regularization_loss: 0.0000e+00 - total_loss: 0.1726\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 4s 26ms/step - root_mean_squared_error: 0.4366 - loss: 0.1894 - regularization_loss: 0.0000e+00 - total_loss: 0.1894\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 4s 28ms/step - root_mean_squared_error: 0.4510 - loss: 0.2021 - regularization_loss: 0.0000e+00 - total_loss: 0.2021\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 4s 30ms/step - root_mean_squared_error: 0.4614 - loss: 0.2116 - regularization_loss: 0.0000e+00 - total_loss: 0.2116\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 4s 31ms/step - root_mean_squared_error: 0.4689 - loss: 0.2186 - regularization_loss: 0.0000e+00 - total_loss: 0.2186\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 4s 28ms/step - root_mean_squared_error: 0.4745 - loss: 0.2239 - regularization_loss: 0.0000e+00 - total_loss: 0.2239\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 3s 25ms/step - root_mean_squared_error: 0.4786 - loss: 0.2279 - regularization_loss: 0.0000e+00 - total_loss: 0.2279\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 4s 27ms/step - root_mean_squared_error: 0.4818 - loss: 0.2310 - regularization_loss: 0.0000e+00 - total_loss: 0.2310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x176370730>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch = 8192\n",
    "test_batch = 4096\n",
    "lr = 0.01\n",
    "epochs=10\n",
    "cached_train = news_train.shuffle(100_000).batch(train_batch).cache()\n",
    "cached_test = news_val.batch(test_batch).cache()\n",
    "model = Reranker(features=['location', 'item_id'], feature_dims=[64, 64], layer_sizes=[64, 32])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=lr))\n",
    "model.fit(cached_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 5s 29ms/step - root_mean_squared_error: 0.1023 - loss: 0.0107 - regularization_loss: 0.0000e+00 - total_loss: 0.0107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 0.10227575898170471,\n",
       " 'loss': 0.011401545256376266,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 0.011401545256376266}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_ranked(model, query_location, candidate_list, n):\n",
    "    query_input = (np.repeat(query_location, len(candidate_list)), candidate_list)\n",
    "    scored_candidates = model.ranking_model(query_input)\n",
    "    results = pd.DataFrame.from_dict({'uri': candidate_list, \"scores\": scored_candidates.numpy().flatten()})\n",
    "    sorted_results = results.sort_values('scores', ascending=False)\n",
    "    print(sorted_results.head(n))\n",
    "    return sorted_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                uri    scores\n",
      "14341                       /news/newsbeat-33148029  0.096374\n",
      "2779              /news/entertainment-arts-55978659  0.096130\n",
      "16584                       /news/newsbeat-35584995  0.093983\n",
      "9867                        /news/newsbeat-24691515  0.093910\n",
      "35955                       /news/uk-wales-55332202  0.093799\n",
      "19389                       /news/newsbeat-39154348  0.093777\n",
      "34485  /news/uk-scotland-highlands-islands-55015585  0.093741\n",
      "21920                     /news/technology-55684595  0.093711\n",
      "23348                             /news/uk-56005071  0.093678\n",
      "35190    /news/uk-scotland-tayside-central-55676707  0.093625\n",
      "36740                       /news/uk-wales-56118730  0.093608\n",
      "41492            /news/world-latin-america-56112386  0.093585\n",
      "17309                       /news/newsbeat-36276060  0.093491\n",
      "39681                   /news/world-europe-39140791  0.093455\n",
      "19863                       /news/newsbeat-39951532  0.093379\n",
      "5360                        /news/newsbeat-12117198  0.093252\n",
      "40955       /news/world-europe-isle-of-man-56175577  0.093217\n",
      "40223                   /news/world-europe-55235802  0.093191\n",
      "25169            /news/uk-england-cornwall-55662409  0.093171\n",
      "3093                          /news/health-53990068  0.093146\n",
      "36320                       /news/uk-wales-55734549  0.093133\n",
      "5754                        /news/newsbeat-12922161  0.093091\n",
      "41514              /news/world-middle-east-38636222  0.093062\n",
      "25253            /news/uk-england-cornwall-56239534  0.093045\n",
      "39016               /news/world-asia-india-55657711  0.093020\n",
      "27603        /news/uk-england-lincolnshire-54914253  0.093000\n",
      "33808                    /news/uk-scotland-55363240  0.093000\n",
      "20604                       /news/newsbeat-41359557  0.092977\n",
      "39234                /news/world-australia-56261504  0.092963\n",
      "8497                        /news/newsbeat-20875268  0.092963\n"
     ]
    }
   ],
   "source": [
    "candidate_list = np.array(unique_item_ids)\n",
    "query_location = 'Newcastle'\n",
    "scored_results = get_top_n_ranked(model, query_location, candidate_list, 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame.from_dict({'uri': candidate_list, \"scores\": scored_candidates.numpy().flatten()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/news/10205571</td>\n",
       "      <td>0.998301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/news/12211968</td>\n",
       "      <td>0.992364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/news/14295731</td>\n",
       "      <td>1.003392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/news/20039682</td>\n",
       "      <td>0.986870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/news/29881189</td>\n",
       "      <td>1.012518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              uri    scores\n",
       "0  /news/10205571  0.998301\n",
       "1  /news/12211968  0.992364\n",
       "2  /news/14295731  1.003392\n",
       "3  /news/20039682  0.986870\n",
       "4  /news/29881189  1.012518"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uri</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38519</th>\n",
       "      <td>/news/world-asia-55368524</td>\n",
       "      <td>1.045556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35453</th>\n",
       "      <td>/news/uk-wales-53565399</td>\n",
       "      <td>1.043822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21728</th>\n",
       "      <td>/news/technology-54974813</td>\n",
       "      <td>1.040119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20869</th>\n",
       "      <td>/news/newsbeat-42026165</td>\n",
       "      <td>1.038186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>/news/business-55009742</td>\n",
       "      <td>1.038104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41793</th>\n",
       "      <td>/news/world-us-canada-24590082</td>\n",
       "      <td>0.957420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>/news/newsbeat-19341268</td>\n",
       "      <td>0.957281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23285</th>\n",
       "      <td>/news/uk-55890224</td>\n",
       "      <td>0.955544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>/news/newsbeat-15886812</td>\n",
       "      <td>0.955402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17844</th>\n",
       "      <td>/news/newsbeat-36832275</td>\n",
       "      <td>0.955356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42732 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  uri    scores\n",
       "38519       /news/world-asia-55368524  1.045556\n",
       "35453         /news/uk-wales-53565399  1.043822\n",
       "21728       /news/technology-54974813  1.040119\n",
       "20869         /news/newsbeat-42026165  1.038186\n",
       "1150          /news/business-55009742  1.038104\n",
       "...                               ...       ...\n",
       "41793  /news/world-us-canada-24590082  0.957420\n",
       "7887          /news/newsbeat-19341268  0.957281\n",
       "23285               /news/uk-55890224  0.955544\n",
       "6726          /news/newsbeat-15886812  0.955402\n",
       "17844         /news/newsbeat-36832275  0.955356\n",
       "\n",
       "[42732 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-recommender-embeddings",
   "language": "python",
   "name": "deep-recommender-embeddings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
